{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26c8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mmap\n",
    "import numpy\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ffmpeg\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from seamless_communication.inference import Translator\n",
    "from seamless_communication.streaming.dataloaders.s2tt import SileroVADSilenceRemover\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42accb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from seamless_communication.inference import Translator\n",
    "from jiwer import wer\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f684e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "\n",
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda\"), # Changed from \"cuda:0\" to \"cpu\"\n",
    "    dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3df637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "def resample_to_16k(audio, orig_sr):\n",
    "    # implement resampling logic here, e.g. torchaudio.transforms.Resample\n",
    "    return torchaudio.transforms.Resample(orig_sr, 16000)(torch.tensor(audio)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe45575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Load Whisper-Large once (outside function, so itâ€™s not reloaded every call)\n",
    "whisper_model = whisper.load_model(\"large-v3\", device=\"cuda\")\n",
    "\n",
    "whisper.audio.FFMPEG_PATH = \"/home/aj/Bhavna/ffmpeg_bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44758216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seamless_communication\n",
    "\n",
    "from seamless_communication.inference import SequenceGeneratorOptions\n",
    "text_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    "    #temperature=0.7,   # 0 for deterministic, >0 adds diversity\n",
    ")\n",
    "\n",
    "# Beam search for unit hypotheses\n",
    "unit_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a213b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8887ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787533a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9937aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a02436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenizer(texts, lang_code):\n",
    "    \"\"\"Apply IndicNLP/Urdu tokenization for Enâ†’Indic evaluation\"\"\"\n",
    "    if not texts:\n",
    "        return texts\n",
    "    elif lang_code in [\"hi\", \"bn\", \"te\", \"ta\", \"ml\", \"kn\", \"gu\", \"mr\", \"pa\", \"or\"]:\n",
    "        return [\" \".join(indic_tokenize.trivial_tokenize(t, lang=lang_code)) for t in texts]\n",
    "    else:  # fallback (English etc.)\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks \n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/input_audios_of_eng\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_tgt_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99703e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_chrf\n",
    "\n",
    "def compute_metrics(src_lang, tgt_lang, references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s):\n",
    "    print(f\"\\nComputing metrics for {src_lang.upper()} â†’ {tgt_lang.upper()}\")\n",
    "\n",
    "    # Normalize hyps\n",
    "    hypotheses_s2tt = [str(h) for h in hypotheses_s2tt]\n",
    "    hypotheses_t2tt = [str(h) for h in hypotheses_t2tt]\n",
    "    predicted_s2s   = [str(h) for h in predicted_s2s]\n",
    "    predicted_t2s   = [str(h) for h in predicted_t2s]\n",
    "\n",
    "    # Normalize refs\n",
    "    references_norm = [[str(r) for r in refset] for refset in references]\n",
    "    multi_references = list(zip(*references_norm))\n",
    "\n",
    "    # ---- Tokenization switch ----\n",
    "    if src_lang == \"en\":  \n",
    "        # Eng â†’ Indic â†’ tokenize target\n",
    "        hypotheses_s2tt = apply_tokenizer(hypotheses_s2tt, tgt_lang)\n",
    "        hypotheses_t2tt = apply_tokenizer(hypotheses_t2tt, tgt_lang)\n",
    "        predicted_s2s   = apply_tokenizer(predicted_s2s, tgt_lang)\n",
    "        predicted_t2s   = apply_tokenizer(predicted_t2s, tgt_lang)\n",
    "        tokenized_refs = [apply_tokenizer(refs, tgt_lang) for refs in multi_references]\n",
    "    else:\n",
    "        # Indic â†’ En â†’ use sacreBLEU default tokenizer\n",
    "        tokenized_refs = multi_references\n",
    "\n",
    "    tokenized_refs = list(zip(*tokenized_refs))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # --------------------\n",
    "    # S2TT\n",
    "    # --------------------\n",
    "    metrics[\"S2TT_BLEU\"]      = corpus_bleu(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF++\"]    = corpus_chrf(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF2++\"]   = corpus_chrf(hypotheses_s2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"S2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_s2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2TT\n",
    "    # --------------------\n",
    "    metrics[\"T2TT_BLEU\"]      = corpus_bleu(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF++\"]    = corpus_chrf(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF2++\"]   = corpus_chrf(hypotheses_t2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"T2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_t2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # S2ST\n",
    "    # --------------------\n",
    "    if predicted_s2s:\n",
    "        metrics[\"S2ST_BLEU\"]    = corpus_bleu(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF++\"]  = corpus_chrf(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF2++\"] = corpus_chrf(predicted_s2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"S2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_s2s)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2ST\n",
    "    # --------------------\n",
    "    if predicted_t2s:\n",
    "        metrics[\"T2ST_BLEU\"]    = corpus_bleu(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF++\"]  = corpus_chrf(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF2++\"] = corpus_chrf(predicted_t2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"T2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_t2s)) / len(references_norm)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d421a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/hin_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1 = run_translation_for_language(\"eng\", \"en_us\", \"hin\", \"hi_in\", full_tasks=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac1ba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: BEN (bn_in)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/ben_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2 = run_translation_for_language(\"eng\", \"en_us\", \"ben\", \"bn_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115f353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/tel_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs3, hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3 = run_translation_for_language(\"eng\", \"en_us\", \"tel\", \"te_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "359618cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TAM (ta_in)\n",
      "============================================================\n",
      "Found 336 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/tam_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4 = run_translation_for_language(\"eng\", \"en_us\", \"tam\", \"ta_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad930618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: MAL (ml_in)\n",
      "============================================================\n",
      "Found 344 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/mal_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs5, hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5 = run_translation_for_language(\"eng\", \"en_us\", \"mal\", \"ml_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ae64d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: KAN (kn_in)\n",
      "============================================================\n",
      "Found 344 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/kan_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs6, hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6 = run_translation_for_language(\"eng\", \"en_us\", \"kan\", \"kn_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "807d2bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: GUJ (gu_in)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/guj_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs7, hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7 = run_translation_for_language(\"eng\", \"en_us\", \"guj\", \"gu_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bb523b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: MAR (mr_in)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/mar_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs8, hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8 = run_translation_for_language(\"eng\", \"en_us\", \"mar\", \"mr_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: PAN (pa_in)\n",
      "============================================================\n",
      "Found 279 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/pan_results.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "refs9, hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9 = run_translation_for_language(\"eng\", \"en_us\", \"pan\", \"pa_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4dce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ORY (or_in)\n",
      "============================================================\n",
      "Found 334 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/ory_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs10, hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10 = run_translation_for_language(\"eng\", \"en_us\", \"ory\", \"or_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03101906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ASM (as_in)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08b3df58834401d9fcfcca579e1dff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082f6ad0cece4940a33ca5b222a753ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/267M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c108b5a3ac3044db94bb3f943edaef14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/656M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707760fe11284490b2e4ed86b34d50d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79a54e07e5f4665a9ef0f13f8ca68cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef22e86c0b16452798486342ad87eb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3da51b43c74c05a2d7b451b92c6f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae5a1e44694168bad2713192d8b985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efda1a4cb81049bc8bf6efd99521e980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/asm_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs11, hyps_s2tt11, hyps_t2tt11, preds_s2s11, preds_t2s11 = run_translation_for_language(\"eng\", \"en_us\", \"asm\", \"as_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae326e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: NPI (ne_np)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c67248b7454273959e1ef5c51c21af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20810f11028341d9b6dc42d0f9d3b596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/174M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a292e234e3164b97bdb862384197747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bb6df2c1264b3fa8a29210d25ef726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd15a4c84f742fea2fa68b982fd4c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e327a757544d464a83b85f4ca9945481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fb213ebec5438c945620515df68333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178f013af99f43edbd5b614cb98b855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f977396d0b942e0a069a917205d728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 343 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/npi_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs12, hyps_s2tt12, hyps_t2tt12, preds_s2s12, preds_t2s12 = run_translation_for_language(\"eng\", \"en_us\", \"npi\",\"ne_np\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3ba900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: SND (sd_in)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1013ff3d77148f4910ec8e0e07072fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c65dfc27f0f4233be59781b59795fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d99f8a55c5141c29d3dae6ac44ab64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/622M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b471083bcf244518a93ec05759129611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a4cd3d1554c7b8bb700013e1bbfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c20872171c9484ab6334a600b273084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3d84e4fa2340ffbd681556e5b002d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463070f52f95427aafa4547bef9ffe9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5646a8826ed441979298fc98c56492cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-Eng-X-Direct/f-Eng-X-Direct-CSVs/snd_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs13, hyps_s2tt13, hyps_t2tt13, preds_s2s13, preds_t2s13 = run_translation_for_language(\"eng\", \"en_us\", \"snd\", \"sd_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4365404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ HI_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 47.20758038942707,\n",
       " 'S2TT_chrF++': 67.1422707430045,\n",
       " 'S2TT_chrF2++': 67.1422707430045,\n",
       " 'S2TT_WER': 0.5858850193121427,\n",
       " 'T2TT_BLEU': 53.05903666964891,\n",
       " 'T2TT_chrF++': 73.29101641233864,\n",
       " 'T2TT_chrF2++': 73.29101641233864,\n",
       " 'T2TT_WER': 0.5608586884988706,\n",
       " 'S2ST_BLEU': 20.078866641712107,\n",
       " 'S2ST_chrF++': 59.323928226195285,\n",
       " 'S2ST_chrF2++': 59.323928226195285,\n",
       " 'S2ST_WER': 0.6807390948093932,\n",
       " 'T2ST_BLEU': 20.2292806480005,\n",
       " 'T2ST_chrF++': 60.11316098674055,\n",
       " 'T2ST_chrF2++': 60.11316098674055,\n",
       " 'T2ST_WER': 0.6835818748195117}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\", \"hi_in\", refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d80c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ BN_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 20.51174794065995,\n",
       " 'S2TT_chrF++': 46.573264080995735,\n",
       " 'S2TT_chrF2++': 46.573264080995735,\n",
       " 'S2TT_WER': 0.7176131372989533,\n",
       " 'T2TT_BLEU': 13.717032573436434,\n",
       " 'T2TT_chrF++': 46.96624079209037,\n",
       " 'T2TT_chrF2++': 46.96624079209037,\n",
       " 'T2TT_WER': 0.7319149032788587,\n",
       " 'S2ST_BLEU': 3.7199102928113716,\n",
       " 'S2ST_chrF++': 37.033558176436685,\n",
       " 'S2ST_chrF2++': 37.033558176436685,\n",
       " 'S2ST_WER': 0.9165609893600437,\n",
       " 'T2ST_BLEU': 3.7199102928113716,\n",
       " 'T2ST_chrF++': 38.61902695277767,\n",
       " 'T2ST_chrF2++': 38.61902695277767,\n",
       " 'T2ST_WER': 0.9288998385967467}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\", \"bn_in\", refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38556c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ TE_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 22.229849552064017,\n",
       " 'S2TT_chrF++': 65.36304413445346,\n",
       " 'S2TT_chrF2++': 65.36304413445346,\n",
       " 'S2TT_WER': 0.6862416954139396,\n",
       " 'T2TT_BLEU': 22.765893232556483,\n",
       " 'T2TT_chrF++': 67.76201712142644,\n",
       " 'T2TT_chrF2++': 67.76201712142644,\n",
       " 'T2TT_WER': 0.6990720558165725,\n",
       " 'S2ST_BLEU': 3.4585921141027356,\n",
       " 'S2ST_chrF++': 31.203694604442983,\n",
       " 'S2ST_chrF2++': 31.203694604442983,\n",
       " 'S2ST_WER': 0.9101295785795336,\n",
       " 'T2ST_BLEU': 3.4585921141027356,\n",
       " 'T2ST_chrF++': 28.79424982029214,\n",
       " 'T2ST_chrF2++': 28.79424982029214,\n",
       " 'T2ST_WER': 0.915643101194562}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"te_in\", refs3, hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d76098c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ TA_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 9.83748990557782,\n",
       " 'S2TT_chrF++': 53.53349693501887,\n",
       " 'S2TT_chrF2++': 53.53349693501887,\n",
       " 'S2TT_WER': 0.7242391794911189,\n",
       " 'T2TT_BLEU': 25.400289715190983,\n",
       " 'T2TT_chrF++': 59.54718891638381,\n",
       " 'T2TT_chrF2++': 59.54718891638381,\n",
       " 'T2TT_WER': 0.7244738057602584}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"ta_in\", refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e048118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ ML_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 20.098339913206324,\n",
       " 'S2TT_chrF++': 63.73427954208568,\n",
       " 'S2TT_chrF2++': 63.73427954208568,\n",
       " 'S2TT_WER': 0.7703561164210542,\n",
       " 'T2TT_BLEU': 8.516593018819643,\n",
       " 'T2TT_chrF++': 56.71883960748831,\n",
       " 'T2TT_chrF2++': 56.71883960748831,\n",
       " 'T2TT_WER': 0.7887866641034194}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"ml_in\", refs5, hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dcef4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ KN_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 8.032276872815308,\n",
       " 'S2TT_chrF++': 52.07141410336956,\n",
       " 'S2TT_chrF2++': 52.07141410336956,\n",
       " 'S2TT_WER': 0.7301583821932678,\n",
       " 'T2TT_BLEU': 15.580105704117443,\n",
       " 'T2TT_chrF++': 58.283865852094785,\n",
       " 'T2TT_chrF2++': 58.283865852094785,\n",
       " 'T2TT_WER': 0.731754491323938}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"kn_in\", refs6, hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d448ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ GU_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 13.508625657351418,\n",
       " 'S2TT_chrF++': 40.02976054989051,\n",
       " 'S2TT_chrF2++': 40.02976054989051,\n",
       " 'S2TT_WER': 0.6773370563588701,\n",
       " 'T2TT_BLEU': 14.009047908905242,\n",
       " 'T2TT_chrF++': 41.014062907013304,\n",
       " 'T2TT_chrF2++': 41.014062907013304,\n",
       " 'T2TT_WER': 0.6827688630383182}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"gu_in\", refs7, hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6734296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ MR_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 15.727800941615351,\n",
       " 'S2TT_chrF++': 51.991014342379735,\n",
       " 'S2TT_chrF2++': 51.991014342379735,\n",
       " 'S2TT_WER': 0.7115384370655192,\n",
       " 'T2TT_BLEU': 14.503996062829852,\n",
       " 'T2TT_chrF++': 54.806454755521806,\n",
       " 'T2TT_chrF2++': 54.806454755521806,\n",
       " 'T2TT_WER': 0.7520936178839361}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"mr_in\", refs8, hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae64c391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ PA_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 37.61370954911621,\n",
       " 'S2TT_chrF++': 59.71624061185019,\n",
       " 'S2TT_chrF2++': 59.71624061185019,\n",
       " 'S2TT_WER': 0.6201570979038564,\n",
       " 'T2TT_BLEU': 30.143352515082135,\n",
       " 'T2TT_chrF++': 52.55582129095531,\n",
       " 'T2TT_chrF2++': 52.55582129095531,\n",
       " 'T2TT_WER': 0.657551606898665}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"pa_in\", refs9, hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2d48508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ OR_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 8.90763711246724,\n",
       " 'S2TT_chrF++': 52.73232032726691,\n",
       " 'S2TT_chrF2++': 52.73232032726691,\n",
       " 'S2TT_WER': 0.7450997409593849,\n",
       " 'T2TT_BLEU': 7.655122720591221,\n",
       " 'T2TT_chrF++': 44.52031608947945,\n",
       " 'T2TT_chrF2++': 44.52031608947945,\n",
       " 'T2TT_WER': 0.8251359523183592}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"or_in\", refs10, hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f468d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ AS_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 4.348949343910558,\n",
       " 'S2TT_chrF++': 46.43426595275811,\n",
       " 'S2TT_chrF2++': 46.43426595275811,\n",
       " 'S2TT_WER': 0.8195492533473043,\n",
       " 'T2TT_BLEU': 8.156196366527345,\n",
       " 'T2TT_chrF++': 54.05801710693592,\n",
       " 'T2TT_chrF2++': 54.05801710693592,\n",
       " 'T2TT_WER': 0.8654719353728063}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"as_in\", refs11, hyps_s2tt11, hyps_t2tt11, preds_s2s11, preds_t2s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cefdf16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ NE_NP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 16.26170171519489,\n",
       " 'S2TT_chrF++': 67.81577468420329,\n",
       " 'S2TT_chrF2++': 67.81577468420329,\n",
       " 'S2TT_WER': 0.731678590318758,\n",
       " 'T2TT_BLEU': 14.247788801610149,\n",
       " 'T2TT_chrF++': 78.63478822198536,\n",
       " 'T2TT_chrF2++': 78.63478822198536,\n",
       " 'T2TT_WER': 0.767599695602735}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"ne_np\", refs12, hyps_s2tt12, hyps_t2tt12, preds_s2s12, preds_t2s12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b3e5cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for EN â†’ SND_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 22.813997135031524,\n",
       " 'S2TT_chrF++': 43.94689607557326,\n",
       " 'S2TT_chrF2++': 43.94689607557326,\n",
       " 'S2TT_WER': 0.6855863957906705,\n",
       " 'T2TT_BLEU': 21.951524426618445,\n",
       " 'T2TT_chrF++': 45.04925955622581,\n",
       " 'T2TT_chrF2++': 45.04925955622581,\n",
       " 'T2TT_WER': 0.7175115345646228}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"en\",\"snd_in\", refs13, hyps_s2tt13, hyps_t2tt13, preds_s2s13, preds_t2s13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ef7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhav_venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
