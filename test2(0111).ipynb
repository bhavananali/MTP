{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3537bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mmap\n",
    "import numpy\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from seamless_communication.inference import Translator\n",
    "from seamless_communication.streaming.dataloaders.s2tt import SileroVADSilenceRemover\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20514f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 09:00:44,390 INFO -- datasets: PyTorch version 2.2.2+cu121 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from seamless_communication.inference import Translator\n",
    "from jiwer import wer\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edce1483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "\n",
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda\"), # Changed from \"cuda:0\" to \"cpu\"\n",
    "    dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c413f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "def resample_to_16k(audio, orig_sr):\n",
    "    # implement resampling logic here, e.g. torchaudio.transforms.Resample\n",
    "    return torchaudio.transforms.Resample(orig_sr, 16000)(torch.tensor(audio)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d571173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import re\n",
    "\n",
    "# Load Whisper-Large once (outside function, so itâ€™s not reloaded every call)\n",
    "whisper_model = whisper.load_model(\"large\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a5033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/home/aj/Bhavna/ffmpeg_bin:\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b582b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "whisper.audio.FFMPEG_PATH = \"/home/aj/Bhavna/ffmpeg_bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8949fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a1c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seamless_communication\n",
    "\n",
    "from seamless_communication.inference import SequenceGeneratorOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0333960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    "    #temperature=0.7,   # 0 for deterministic, >0 adds diversity\n",
    ")\n",
    "\n",
    "# Beam search for unit hypotheses\n",
    "unit_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ccae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639dad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from whisper.normalizers.basic import BasicTextNormalizer\n",
    "#normalize_s= BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f02f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs\"):\n",
    "    import os\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")\n",
    "\n",
    "def run_translation_for_language(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/input_audios_of_eng\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_tgt_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "293b153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu, corpus_chrf\n",
    "from jiwer import wer\n",
    "\n",
    "def compute_metrics(lang_code, references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s):\n",
    "    print(f\"\\nComputing metrics for language: {lang_code.upper()}\")\n",
    "    # Normalize hyps\n",
    "    hypotheses_s2tt = [\" \".join(h) if isinstance(h, list) else str(h) for h in hypotheses_s2tt]\n",
    "    hypotheses_t2tt = [\" \".join(h) if isinstance(h, list) else str(h) for h in hypotheses_t2tt]\n",
    "    predicted_s2s   = [\" \".join(h) if isinstance(h, list) else str(h) for h in predicted_s2s]\n",
    "    predicted_t2s   = [\" \".join(h) if isinstance(h, list) else str(h) for h in predicted_t2s]\n",
    "\n",
    "    # Normalize refs\n",
    "    references_norm = []\n",
    "    for refset in references:\n",
    "        references_norm.append([\" \".join(r) if isinstance(r, list) else str(r) for r in refset])\n",
    "    multi_references = list(zip(*references_norm))  # multiple references per sentence\n",
    "\n",
    "    metrics = {}\n",
    "    # Text-to-text & speech-to-text\n",
    "    metrics[\"S2TT_SacreBLEU\"] = corpus_bleu(hypotheses_s2tt, multi_references).score\n",
    "    metrics[\"T2TT_chrF2++\"]   = corpus_chrf(hypotheses_t2tt, multi_references).score\n",
    "    metrics[\"S2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_s2tt)) / len(references_norm)\n",
    "    metrics[\"T2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_t2tt)) / len(references_norm)\n",
    "\n",
    "    # Speech-to-speech (decoded to text for scoring)\n",
    "    if predicted_s2s:\n",
    "        metrics[\"S2ST_ASR_WER\"]  = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_s2s)) / len(references_norm)\n",
    "        metrics[\"S2ST_ASR_BLEU\"] = corpus_bleu(predicted_s2s, multi_references).score\n",
    "\n",
    "    if predicted_t2s:\n",
    "        metrics[\"T2ST_ASR_WER\"]  = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_t2s)) / len(references_norm)\n",
    "        metrics[\"T2ST_ASR_BLEU\"] = corpus_bleu(predicted_t2s, multi_references).score\n",
    "        \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681733e",
   "metadata": {},
   "source": [
    "**eng-X metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "007cfa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs/tel_results.csv\n",
      "\n",
      "Computing metrics for language: TEL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 19.768624174201648,\n",
       " 'T2TT_chrF2++': 57.88079557608407,\n",
       " 'S2TT_WER': 0.6862416954139396,\n",
       " 'T2TT_WER': 0.6990720558165725,\n",
       " 'S2ST_ASR_WER': 0.9101295785795336,\n",
       " 'S2ST_ASR_BLEU': 1.845789027182998,\n",
       " 'T2ST_ASR_WER': 0.915643101194562,\n",
       " 'T2ST_ASR_BLEU': 1.9749424059894964}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs, s2tt, t2tt, s2s, t2s=run_translation_for_language(\"eng\", \"en_us\",\"tel\",\"te_in\",full_tasks=True)\n",
    "compute_metrics(\"tel\", refs, s2tt, t2tt, s2s, t2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c64301d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs/hin_results.csv\n",
      "\n",
      "Computing metrics for language: HIN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 31.153900191619226,\n",
       " 'T2TT_chrF2++': 57.8105727684805,\n",
       " 'S2TT_WER': 0.5858850193121427,\n",
       " 'T2TT_WER': 0.5608586884988706,\n",
       " 'S2ST_ASR_WER': 0.6807390948093932,\n",
       " 'S2ST_ASR_BLEU': 18.34571223405713,\n",
       " 'T2ST_ASR_WER': 0.6835818748195117,\n",
       " 'T2ST_ASR_BLEU': 17.849980255040418}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs3, s2tt3, t2tt3, s2s3, t2s3=run_translation_for_language(\"eng\", \"en_us\",\"hin\",\"hi_in\",full_tasks=True)\n",
    "compute_metrics(\"hin\", refs3, s2tt3, t2tt3, s2s3, t2s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0b9e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: URD (ur_pk)\n",
      "============================================================\n",
      "Found 230 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs/urd_results.csv\n",
      "\n",
      "Computing metrics for language: URD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 20.950129624567204,\n",
       " 'T2TT_chrF2++': 48.24124829628641,\n",
       " 'S2TT_WER': 0.6851889290883566,\n",
       " 'T2TT_WER': 0.6800507771805084,\n",
       " 'S2ST_ASR_WER': 0.6800128376390979,\n",
       " 'S2ST_ASR_BLEU': 20.440529931026514,\n",
       " 'T2ST_ASR_WER': 0.6907736706233382,\n",
       " 'T2ST_ASR_BLEU': 19.420914598331493}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs4, s2tt4, t2tt4, s2s4, t2s4=run_translation_for_language(\"eng\", \"en_us\",\"urd\",\"ur_pk\",full_tasks=True)\n",
    "compute_metrics(\"urd\", refs4, s2tt4, t2tt4, s2s4, t2s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb62c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TAM (ta_in)\n",
      "============================================================\n",
      "Found 336 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs/tam_results.csv\n",
      "\n",
      "Computing metrics for language: TAM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 14.274613106193202,\n",
       " 'T2TT_chrF2++': 56.90018770799228,\n",
       " 'S2TT_WER': 0.7242391794911189,\n",
       " 'T2TT_WER': 0.7244738057602584}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs1, s2tt1, t2tt1, s2s1, t2s1=run_translation_for_language(\"eng\", \"en_us\",\"tam\",\"ta_in\",full_tasks=False)\n",
    "compute_metrics(\"tam\", refs1, s2tt1, t2tt1, s2s1, t2s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c5c0e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ORY (or_in)\n",
      "============================================================\n",
      "Found 334 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/eng-X/outputs/ory_results.csv\n",
      "\n",
      "Computing metrics for language: ORY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 14.299858776616398,\n",
       " 'T2TT_chrF2++': 44.936253311409345,\n",
       " 'S2TT_WER': 0.7450997409593849,\n",
       " 'T2TT_WER': 0.8251359523183592}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs2, s2tt2, t2tt2, s2s2, t2s2=run_translation_for_language(\"eng\", \"en_us\",\"ory\",\"or_in\",full_tasks=False)\n",
    "compute_metrics(\"ory\", refs2, s2tt2, t2tt2, s2s2, t2s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8f770",
   "metadata": {},
   "source": [
    "**X-eng metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f937cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs\"):\n",
    "    import os\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language_eng(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/input_audios_of_langs\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_src_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\",tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_src_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_src_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_src_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff562181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs/hin_results.csv\n",
      "\n",
      "Computing metrics for language: HIN->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 30.100699940404887,\n",
       " 'T2TT_chrF2++': 64.43126015394755,\n",
       " 'S2TT_WER': 0.5769781283054644,\n",
       " 'T2TT_WER': 0.4829589650612814,\n",
       " 'S2ST_ASR_WER': 0.5744392525630683,\n",
       " 'S2ST_ASR_BLEU': 29.80706185581536,\n",
       " 'T2ST_ASR_WER': 0.5062129707006541,\n",
       " 'T2ST_ASR_BLEU': 35.03781892627364}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs5, s2tt5, t2tt5, s2s5, t2s5=run_translation_for_language_eng(\"hin\", \"hi_in\",\"eng\",\"en_us\",full_tasks=True)\n",
    "compute_metrics(\"hin->eng\", refs5, s2tt5, t2tt5, s2s5, t2s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef17ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs/tel_results.csv\n",
      "\n",
      "Computing metrics for language: TEL->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 25.751960658772255,\n",
       " 'T2TT_chrF2++': 62.46116400263574,\n",
       " 'S2TT_WER': 0.6132852423109971,\n",
       " 'T2TT_WER': 0.5262495941621558,\n",
       " 'S2ST_ASR_WER': 0.6039635892802974,\n",
       " 'S2ST_ASR_BLEU': 25.96858004991482,\n",
       " 'T2ST_ASR_WER': 0.5351444780751428,\n",
       " 'T2ST_ASR_BLEU': 33.068577804727255}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs6, s2tt6, t2tt6, s2s6, t2s6=run_translation_for_language_eng(\"tel\", \"te_in\",\"eng\",\"en_us\",full_tasks=True)\n",
    "compute_metrics(\"tel->eng\", refs6, s2tt6, t2tt6, s2s6, t2s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bba6903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 336 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs/tam_results.csv\n",
      "\n",
      "Computing metrics for language: TAM->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 23.350509110207998,\n",
       " 'T2TT_chrF2++': 58.19404045684811,\n",
       " 'S2TT_WER': 0.6711805367864453,\n",
       " 'T2TT_WER': 0.5663497144591616,\n",
       " 'S2ST_ASR_WER': 0.658504086797589,\n",
       " 'S2ST_ASR_BLEU': 23.523496058910386,\n",
       " 'T2ST_ASR_WER': 0.5782981519860814,\n",
       " 'T2ST_ASR_BLEU': 28.455894567053345}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs7, s2tt7, t2tt7, s2s7, t2s7=run_translation_for_language_eng(\"tam\", \"ta_in\",\"eng\",\"en_us\",full_tasks=True)\n",
    "compute_metrics(\"tam->eng\", refs7, s2tt7, t2tt7, s2s7, t2s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "156f3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 230 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs/urd_results.csv\n",
      "\n",
      "Computing metrics for language: URD->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 24.751033511752947,\n",
       " 'T2TT_chrF2++': 61.60675535444684,\n",
       " 'S2TT_WER': 0.6189562220362608,\n",
       " 'T2TT_WER': 0.5121603399715183,\n",
       " 'S2ST_ASR_WER': 0.6145540594050083,\n",
       " 'S2ST_ASR_BLEU': 24.992822228880737,\n",
       " 'T2ST_ASR_WER': 0.516878890245686,\n",
       " 'T2ST_ASR_BLEU': 33.12744858731363}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs8, s2tt8, t2tt8, s2s8, t2s8=run_translation_for_language_eng(\"urd\", \"ur_pk\",\"eng\",\"en_us\",full_tasks=True)\n",
    "compute_metrics(\"urd->eng\", refs8, s2tt8, t2tt8, s2s8, t2s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bd62d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 334 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/Project/X-eng/outputs/ory_results.csv\n",
      "\n",
      "Computing metrics for language: ORY->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_SacreBLEU': 26.861764973835275,\n",
       " 'T2TT_chrF2++': 63.70346590715455,\n",
       " 'S2TT_WER': 0.6275503817546304,\n",
       " 'T2TT_WER': 0.5113733669275848,\n",
       " 'S2ST_ASR_WER': 0.6268162642308952,\n",
       " 'S2ST_ASR_BLEU': 26.91504263695809,\n",
       " 'T2ST_ASR_WER': 0.5130236769776545,\n",
       " 'T2ST_ASR_BLEU': 34.68284905623634}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs9, s2tt9, t2tt9, s2s9, t2s9=run_translation_for_language_eng(\"ory\", \"or_in\",\"eng\",\"en_us\",full_tasks=True)\n",
    "compute_metrics(\"ory->eng\", refs9, s2tt9, t2tt9, s2s9, t2s9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ba13e",
   "metadata": {},
   "source": [
    "**S2T->T2S pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef67888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language_s2s(sm4t_src_lang, fleurs_src_lang, sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references = []\n",
    "    predicted_s2t_t2s = []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        # Resample if needed\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        # Convert numpy â†’ torch.FloatTensor, add batch dimension if 1D\n",
    "        src_audio = torch.tensor(src_audio, dtype=torch.float32)\n",
    "        # Current: (1, seq_len)\n",
    "        if src_audio.ndim == 2 and src_audio.shape[0] == 1:\n",
    "            src_audio = src_audio.transpose(0, 1)   # (seq_len, 1)\n",
    "\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2TT ---\n",
    "            s2tt_out, _ = translator.predict(\n",
    "                input=src_audio,\n",
    "                task_str=\"s2tt\",\n",
    "                tgt_lang=sm4t_tgt_lang,\n",
    "                text_generation_opts=text_opts\n",
    "            )\n",
    "\n",
    "            # --- T2ST ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=str(s2tt_out[0]),\n",
    "                task_str=\"t2st\",\n",
    "                src_lang=sm4t_src_lang,\n",
    "                tgt_lang=sm4t_tgt_lang,\n",
    "                text_generation_opts=text_opts,\n",
    "                unit_generation_opts=unit_opts\n",
    "            )\n",
    "\n",
    "            # Save generated speech\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/Project/s2t-t2s/s2t-t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            # Ensure tensor is (channels, time)\n",
    "            audio_tensor = t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu()\n",
    "            if audio_tensor.ndim == 1:\n",
    "                audio_tensor = audio_tensor.unsqueeze(0)\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                audio_tensor,\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Whisper ASR on synthesized speech\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2t_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    return references, predicted_s2t_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515c85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_s2s(lang_code, references, predicted_s2t_t2s):\n",
    "    print(f\"\\nComputing metrics for language: {lang_code.upper()}\")\n",
    "\n",
    "    # Normalize hypotheses\n",
    "    predicted_s2t_t2s = [\" \".join(h) if isinstance(h, list) else str(h) for h in predicted_s2t_t2s]\n",
    "\n",
    "    # Normalize references\n",
    "    references_norm = []\n",
    "    for refset in references:\n",
    "        references_norm.append([\" \".join(r) if isinstance(r, list) else str(r) for r in refset])\n",
    "\n",
    "    metrics = {}\n",
    "    if predicted_s2t_t2s:\n",
    "        metrics[\"S2T+T2S_ASR_WER\"] = sum(\n",
    "            wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_s2t_t2s)\n",
    "        ) / len(references_norm)\n",
    "\n",
    "        metrics[\"S2T+T2S_ASR_BLEU\"] = corpus_bleu(\n",
    "            predicted_s2t_t2s, list(zip(*references_norm))\n",
    "        ).score\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2930e1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "\n",
      "Computing metrics for language: ENG->TEL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.9101285191293687, 'S2T+T2S_ASR_BLEU': 2.3390303440246676}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref,s2s_p=run_translation_for_language_s2s(\"eng\", \"en_us\",\"tel\",\"te_in\",full_tasks=True)\n",
    "compute_metrics_s2s(\"eng->tel\", ref, s2s_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71425693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "\n",
      "Computing metrics for language: ENG->HIN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6804263902727953, 'S2T+T2S_ASR_BLEU': 18.01060195105432}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref1,s2s_p1=run_translation_for_language_s2s(\"eng\", \"en_us\",\"hin\",\"hi_in\",full_tasks=True)\n",
    "compute_metrics_s2s(\"eng->hin\", ref1, s2s_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ed5e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: URD (ur_pk)\n",
      "============================================================\n",
      "Found 230 parallel sentences\n",
      "\n",
      "Computing metrics for language: ENG->URD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6790183352396314, 'S2T+T2S_ASR_BLEU': 20.578279757322075}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref2,s2s_p2=run_translation_for_language_s2s(\"eng\", \"en_us\",\"urd\",\"ur_pk\",full_tasks=True)\n",
    "compute_metrics_s2s(\"eng->urd\", ref2, s2s_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f6fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "\n",
      "Computing metrics for language: TEL->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6243740005863173, 'S2T+T2S_ASR_BLEU': 25.323806971836365}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref3, s2s_p3=run_translation_for_language_s2s(\"tel\",\"te_in\",\"eng\", \"en_us\",full_tasks=True)\n",
    "compute_metrics_s2s(\"tel->eng\", ref3, s2s_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc1aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "\n",
      "Computing metrics for language: HIN->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6022611520626794, 'S2T+T2S_ASR_BLEU': 27.8533757068395}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref4, s2s_p4=run_translation_for_language_s2s(\"hin\",\"hi_in\",\"eng\", \"en_us\",full_tasks=True)\n",
    "compute_metrics_s2s(\"hin->eng\", ref4, s2s_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5b9578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 230 parallel sentences\n",
      "\n",
      "Computing metrics for language: URD->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6160407029699605, 'S2T+T2S_ASR_BLEU': 24.260052353074}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref5,s2s_p5=run_translation_for_language_s2s(\"urd\",\"ur_pk\",\"eng\", \"en_us\",full_tasks=True)\n",
    "compute_metrics_s2s(\"urd->eng\", ref5, s2s_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d865fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 334 parallel sentences\n",
      "\n",
      "Computing metrics for language: ORY->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6271728590792701, 'S2T+T2S_ASR_BLEU': 26.918422328215055}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref6, s2s_p6=run_translation_for_language_s2s(\"ory\",\"or_in\",\"eng\", \"en_us\",full_tasks=True)\n",
    "compute_metrics_s2s(\"ory->eng\", ref6, s2s_p6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e155d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 336 parallel sentences\n",
      "\n",
      "Computing metrics for language: TAM->ENG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2T+T2S_ASR_WER': 0.6603241781688973, 'S2T+T2S_ASR_BLEU': 23.356889157087096}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref7, s2s_p7=run_translation_for_language_s2s(\"tam\",\"ta_in\",\"eng\", \"en_us\",full_tasks=True)\n",
    "compute_metrics_s2s(\"tam->eng\", ref7, s2s_p7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhav_venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
