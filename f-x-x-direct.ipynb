{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862f50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mmap\n",
    "import numpy\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ffmpeg\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from seamless_communication.inference import Translator\n",
    "from seamless_communication.streaming.dataloaders.s2tt import SileroVADSilenceRemover\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d88bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from seamless_communication.inference import Translator\n",
    "from jiwer import wer\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484a5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "\n",
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda\"), # Changed from \"cuda:0\" to \"cpu\"\n",
    "    dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944504c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "def resample_to_16k(audio, orig_sr):\n",
    "    # implement resampling logic here, e.g. torchaudio.transforms.Resample\n",
    "    return torchaudio.transforms.Resample(orig_sr, 16000)(torch.tensor(audio)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be598d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Load Whisper-Large once (outside function, so itâ€™s not reloaded every call)\n",
    "whisper_model = whisper.load_model(\"large-v3\", device=\"cuda\")\n",
    "\n",
    "whisper.audio.FFMPEG_PATH = \"/home/aj/Bhavna/ffmpeg_bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c02b8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e55d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf81552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79a3dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seamless_communication\n",
    "\n",
    "from seamless_communication.inference import SequenceGeneratorOptions\n",
    "text_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    "    #temperature=0.7,   # 0 for deterministic, >0 adds diversity\n",
    ")\n",
    "\n",
    "# Beam search for unit hypotheses\n",
    "unit_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "545aec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e52f40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenizer(texts, lang_code):\n",
    "    \"\"\"Apply IndicNLP/Urdu tokenization for Enâ†’Indic evaluation\"\"\"\n",
    "    if not texts:\n",
    "        return texts\n",
    "    elif lang_code in [\"hi\", \"bn\", \"te\", \"ta\", \"ml\", \"kn\", \"gu\", \"mr\", \"pa\", \"or\"]:\n",
    "        return [\" \".join(indic_tokenize.trivial_tokenize(t, lang=lang_code)) for t in texts]\n",
    "    else:  # fallback (English etc.)\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3406126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/input_audios\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_tgt_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_tgt_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c587cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_chrf\n",
    "\n",
    "def compute_metrics(src_lang, tgt_lang, references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s):\n",
    "    print(f\"\\nComputing metrics for {src_lang.upper()} â†’ {tgt_lang.upper()}\")\n",
    "\n",
    "    # Normalize hyps\n",
    "    hypotheses_s2tt = [str(h) for h in hypotheses_s2tt]\n",
    "    hypotheses_t2tt = [str(h) for h in hypotheses_t2tt]\n",
    "    predicted_s2s   = [str(h) for h in predicted_s2s]\n",
    "    predicted_t2s   = [str(h) for h in predicted_t2s]\n",
    "\n",
    "    # Normalize refs\n",
    "    references_norm = [[str(r) for r in refset] for refset in references]\n",
    "    multi_references = list(zip(*references_norm))\n",
    "\n",
    "    # ---- Tokenization switch ----\n",
    "    if src_lang == \"en\":  \n",
    "        # Eng â†’ Indic â†’ tokenize target\n",
    "        hypotheses_s2tt = apply_tokenizer(hypotheses_s2tt, tgt_lang)\n",
    "        hypotheses_t2tt = apply_tokenizer(hypotheses_t2tt, tgt_lang)\n",
    "        predicted_s2s   = apply_tokenizer(predicted_s2s, tgt_lang)\n",
    "        predicted_t2s   = apply_tokenizer(predicted_t2s, tgt_lang)\n",
    "        tokenized_refs = [apply_tokenizer(refs, tgt_lang) for refs in multi_references]\n",
    "    else:\n",
    "        # Indic â†’ En â†’ use sacreBLEU default tokenizer\n",
    "        tokenized_refs = multi_references\n",
    "\n",
    "    tokenized_refs = list(zip(*tokenized_refs))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # --------------------\n",
    "    # S2TT\n",
    "    # --------------------\n",
    "    metrics[\"S2TT_BLEU\"]      = corpus_bleu(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF++\"]    = corpus_chrf(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF2++\"]   = corpus_chrf(hypotheses_s2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"S2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_s2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2TT\n",
    "    # --------------------\n",
    "    metrics[\"T2TT_BLEU\"]      = corpus_bleu(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF++\"]    = corpus_chrf(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF2++\"]   = corpus_chrf(hypotheses_t2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"T2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_t2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # S2ST\n",
    "    # --------------------\n",
    "    if predicted_s2s:\n",
    "        metrics[\"S2ST_BLEU\"]    = corpus_bleu(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF++\"]  = corpus_chrf(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF2++\"] = corpus_chrf(predicted_s2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"S2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_s2s)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2ST\n",
    "    # --------------------\n",
    "    if predicted_t2s:\n",
    "        metrics[\"T2ST_BLEU\"]    = corpus_bleu(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF++\"]  = corpus_chrf(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF2++\"] = corpus_chrf(predicted_t2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"T2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_t2s)) / len(references_norm)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c600201",
   "metadata": {},
   "source": [
    "**North**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "926adc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: MAR (mr_in)\n",
      "============================================================\n",
      "Found 264 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/mar_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1 = run_translation_for_language(\"hin\", \"hi_in\",\"mar\",\"mr_in\", full_tasks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fce54e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for HIN â†’ MR_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 7.859438681510603,\n",
       " 'S2TT_chrF++': 46.507914690966345,\n",
       " 'S2TT_chrF2++': 46.507914690966345,\n",
       " 'S2TT_WER': 0.8490564509807691,\n",
       " 'T2TT_BLEU': 27.22589423069701,\n",
       " 'T2TT_chrF++': 57.39669578850625,\n",
       " 'T2TT_chrF2++': 57.39669578850625,\n",
       " 'T2TT_WER': 0.812781223835248}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"hin\",\"mr_in\", refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ec725ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: NPI (ne_np)\n",
      "============================================================\n",
      "Found 260 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/npi_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2 = run_translation_for_language(\"hin\",\"hi_in\",\"npi\",\"ne_np\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00949b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for HIN â†’ NE_NP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 25.33654946448646,\n",
       " 'S2TT_chrF++': 64.99473106349947,\n",
       " 'S2TT_chrF2++': 64.99473106349947,\n",
       " 'S2TT_WER': 0.8399920090949645,\n",
       " 'T2TT_BLEU': 21.651956746181064,\n",
       " 'T2TT_chrF++': 68.10030674738218,\n",
       " 'T2TT_chrF2++': 68.10030674738218,\n",
       " 'T2TT_WER': 0.8087716672999247}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"hin\",\"ne_np\", refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36f002d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: URD (ur_pk)\n",
      "============================================================\n",
      "Found 176 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/urd_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs5, hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5 = run_translation_for_language(\"hin\",\"hi_in\",\"urd\",\"ur_pk\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ec89670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for HIN â†’ UR_PK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 9.42119686197517,\n",
       " 'S2TT_chrF++': 34.73328567381309,\n",
       " 'S2TT_chrF2++': 34.73328567381309,\n",
       " 'S2TT_WER': 0.7461084350137203,\n",
       " 'T2TT_BLEU': 8.508341296101372,\n",
       " 'T2TT_chrF++': 34.0999525664329,\n",
       " 'T2TT_chrF2++': 34.0999525664329,\n",
       " 'T2TT_WER': 0.7155139423986123,\n",
       " 'S2ST_BLEU': 8.329829723842051,\n",
       " 'S2ST_chrF++': 31.896050576254524,\n",
       " 'S2ST_chrF2++': 31.896050576254524,\n",
       " 'S2ST_WER': 0.7592791765820599,\n",
       " 'T2ST_BLEU': 8.197162980930852,\n",
       " 'T2ST_chrF++': 33.995066590239674,\n",
       " 'T2ST_chrF2++': 33.995066590239674,\n",
       " 'T2ST_WER': 0.7412146675340211}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"hin\",\"ur_pk\", refs5, hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e9462",
   "metadata": {},
   "source": [
    "**West**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94b2c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: PAN (pa_in)\n",
      "============================================================\n",
      "Found 278 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/pan_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs3,hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3 = run_translation_for_language(\"guj\",\"gu_in\",\"pan\",\"pa_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50373cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for GUJ â†’ PA_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 13.826777579228938,\n",
       " 'S2TT_chrF++': 41.951670925291666,\n",
       " 'S2TT_chrF2++': 41.951670925291666,\n",
       " 'S2TT_WER': 0.743335535162905,\n",
       " 'T2TT_BLEU': 12.021577610863728,\n",
       " 'T2TT_chrF++': 38.875269796901364,\n",
       " 'T2TT_chrF2++': 38.875269796901364,\n",
       " 'T2TT_WER': 0.7435963691415168}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"guj\",\"pa_in\", refs3, hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eec5f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: GUJ (gu_in)\n",
      "============================================================\n",
      "Found 278 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/guj_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4 = run_translation_for_language(\"pan\",\"pa_in\",\"guj\",\"gu_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a945a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for PAN â†’ GU_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 4.6192151051305474,\n",
       " 'S2TT_chrF++': 31.822103844478995,\n",
       " 'S2TT_chrF2++': 31.822103844478995,\n",
       " 'S2TT_WER': 0.8223669055613883,\n",
       " 'T2TT_BLEU': 4.444587794585869,\n",
       " 'T2TT_chrF++': 30.837545402859195,\n",
       " 'T2TT_chrF2++': 30.837545402859195,\n",
       " 'T2TT_WER': 0.8018523434687755}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"pan\",\"gu_in\", refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97a803",
   "metadata": {},
   "source": [
    "**East**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46738f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ORY (or_in)\n",
      "============================================================\n",
      "Found 333 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/ory_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs6, hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6 = run_translation_for_language(\"ben\",\"bn_in\",\"ory\",\"or_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a521067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for BEN â†’ OR_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 6.917184228205472,\n",
       " 'S2TT_chrF++': 34.89762454148601,\n",
       " 'S2TT_chrF2++': 34.89762454148601,\n",
       " 'S2TT_WER': 0.8717856015394257,\n",
       " 'T2TT_BLEU': 7.474875887495341,\n",
       " 'T2TT_chrF++': 38.20305627425529,\n",
       " 'T2TT_chrF2++': 38.20305627425529,\n",
       " 'T2TT_WER': 0.8267578894870617}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"ben\",\"or_in\", refs6, hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a7c116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ASM (as_in)\n",
      "============================================================\n",
      "Found 348 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/asm_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs7, hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7 = run_translation_for_language(\"ben\",\"bn_in\",\"asm\",\"as_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01ddd3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for BEN â†’ AS_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 9.55204080682377,\n",
       " 'S2TT_chrF++': 35.50819437364589,\n",
       " 'S2TT_chrF2++': 35.50819437364589,\n",
       " 'S2TT_WER': 0.8950376965191159,\n",
       " 'T2TT_BLEU': 9.55204080682377,\n",
       " 'T2TT_chrF++': 31.686870720549855,\n",
       " 'T2TT_chrF2++': 31.686870720549855,\n",
       " 'T2TT_WER': 0.8711566243900262}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"ben\",\"as_in\", refs7, hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e13038",
   "metadata": {},
   "source": [
    "**South**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06d4dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TAM (ta_in)\n",
      "============================================================\n",
      "Found 292 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/tam_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs8, hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8 = run_translation_for_language(\"tel\",\"te_in\",\"tam\",\"ta_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c37ca60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TEL â†’ TA_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 9.238430210261097,\n",
       " 'S2TT_chrF++': 50.582031194781564,\n",
       " 'S2TT_chrF2++': 50.582031194781564,\n",
       " 'S2TT_WER': 0.8921039304658651,\n",
       " 'T2TT_BLEU': 9.238430210261097,\n",
       " 'T2TT_chrF++': 50.031995265030716,\n",
       " 'T2TT_chrF2++': 50.031995265030716,\n",
       " 'T2TT_WER': 0.8598565162295395}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tel\",\"ta_in\", refs8, hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca04de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: MAL (ml_in)\n",
      "============================================================\n",
      "Found 298 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/mal_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs9, hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9 = run_translation_for_language(\"tel\",\"te_in\",\"mal\",\"ml_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfc54dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TEL â†’ ML_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 4.016138436407654,\n",
       " 'S2TT_chrF++': 31.052630186576106,\n",
       " 'S2TT_chrF2++': 31.052630186576106,\n",
       " 'S2TT_WER': 0.918123165156763,\n",
       " 'T2TT_BLEU': 7.141816289329644,\n",
       " 'T2TT_chrF++': 39.42443373108362,\n",
       " 'T2TT_chrF2++': 39.42443373108362,\n",
       " 'T2TT_WER': 0.8735299979184779}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tel\",\"ml_in\", refs9, hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aabb7728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: KAN (kn_in)\n",
      "============================================================\n",
      "Found 297 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/f-X-X-Direct-CSVs/kan_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs10, hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10 = run_translation_for_language(\"tel\",\"te_in\",\"kan\",\"kn_in\", full_tasks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b5d636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TEL â†’ KN_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 4.065425428798724,\n",
       " 'S2TT_chrF++': 46.04671936551367,\n",
       " 'S2TT_chrF2++': 46.04671936551367,\n",
       " 'S2TT_WER': 0.8890393484051732,\n",
       " 'T2TT_BLEU': 4.065425428798724,\n",
       " 'T2TT_chrF++': 40.71791994262089,\n",
       " 'T2TT_chrF2++': 40.71791994262089,\n",
       " 'T2TT_WER': 0.8218582429619888}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tel\",\"kn_in\", refs10, hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97de41d",
   "metadata": {},
   "source": [
    "**Reverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96606727",
   "metadata": {},
   "source": [
    "**North**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3acee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "134c5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/input_audios\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_src_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e2c8593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 264 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/mar_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs1_r, hyps_s2tt1_r, hyps_t2tt1_r, preds_s2s1_r, preds_t2s1_r = run_translation_for_language(\"mar\",\"mr_in\",\"hin\", \"hi_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16d61135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for MAR â†’ HI_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 6.464941342480946,\n",
       " 'S2TT_chrF++': 42.35185330359103,\n",
       " 'S2TT_chrF2++': 42.35185330359103,\n",
       " 'S2TT_WER': 0.7889982156704974,\n",
       " 'T2TT_BLEU': 20.038908500140973,\n",
       " 'T2TT_chrF++': 50.3440705551925,\n",
       " 'T2TT_chrF2++': 50.3440705551925,\n",
       " 'T2TT_WER': 0.7165888577509504,\n",
       " 'S2ST_BLEU': 6.464941342480946,\n",
       " 'S2ST_chrF++': 38.352288772663755,\n",
       " 'S2ST_chrF2++': 38.352288772663755,\n",
       " 'S2ST_WER': 0.826925291130424,\n",
       " 'T2ST_BLEU': 7.126955677090929,\n",
       " 'T2ST_chrF++': 40.33802140332752,\n",
       " 'T2ST_chrF2++': 40.33802140332752,\n",
       " 'T2ST_WER': 0.8048305062268768}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"mar\",\"hi_in\", refs1_r, hyps_s2tt1_r, hyps_t2tt1_r, preds_s2s1_r, preds_t2s1_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b9eb25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 260 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/npi_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs2_r, hyps_s2tt2_r, hyps_t2tt2_r, preds_s2s2_r, preds_t2s2_r = run_translation_for_language(\"npi\",\"ne_np\",\"hin\",\"hi_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d13a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for NPI â†’ HI_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 27.130567714631198,\n",
       " 'S2TT_chrF++': 58.301010970186255,\n",
       " 'S2TT_chrF2++': 58.301010970186255,\n",
       " 'S2TT_WER': 0.7487081372317297,\n",
       " 'T2TT_BLEU': 43.59493824807389,\n",
       " 'T2TT_chrF++': 68.20801255338704,\n",
       " 'T2TT_chrF2++': 68.20801255338704,\n",
       " 'T2TT_WER': 0.6692514937056953,\n",
       " 'S2ST_BLEU': 27.065739132597326,\n",
       " 'S2ST_chrF++': 56.455187994813,\n",
       " 'S2ST_chrF2++': 56.455187994813,\n",
       " 'S2ST_WER': 0.8120408481160151,\n",
       " 'T2ST_BLEU': 39.42058093215872,\n",
       " 'T2ST_chrF++': 68.92644962306159,\n",
       " 'T2ST_chrF2++': 68.92644962306159,\n",
       " 'T2ST_WER': 0.7699160556570889}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"npi\",\"hi_in\", refs2_r, hyps_s2tt2_r, hyps_t2tt2_r, preds_s2s2_r, preds_t2s2_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a353ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: HIN (hi_in)\n",
      "============================================================\n",
      "Found 176 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/urd_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs5_r, hyps_s2tt5_r, hyps_t2tt5_r, preds_s2s5_r, preds_t2s5_r = run_translation_for_language(\"urd\",\"ur_pk\",\"hin\",\"hi_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e7d29bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for URD â†’ HI_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 8.607692533178168,\n",
       " 'S2TT_chrF++': 41.19010078610498,\n",
       " 'S2TT_chrF2++': 41.19010078610498,\n",
       " 'S2TT_WER': 0.7717452958864062,\n",
       " 'T2TT_BLEU': 9.035807436368023,\n",
       " 'T2TT_chrF++': 39.42884552704032,\n",
       " 'T2TT_chrF2++': 39.42884552704032,\n",
       " 'T2TT_WER': 0.754861134035603,\n",
       " 'S2ST_BLEU': 8.149723365644475,\n",
       " 'S2ST_chrF++': 36.20660403901591,\n",
       " 'S2ST_chrF2++': 36.20660403901591,\n",
       " 'S2ST_WER': 0.8304131184239142,\n",
       " 'T2ST_BLEU': 8.739145705346058,\n",
       " 'T2ST_chrF++': 37.63534755633244,\n",
       " 'T2ST_chrF2++': 37.63534755633244,\n",
       " 'T2ST_WER': 0.835272110674643}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"urd\",\"hi_in\", refs5_r, hyps_s2tt5_r, hyps_t2tt5_r, preds_s2s5_r, preds_t2s5_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b72b6",
   "metadata": {},
   "source": [
    "**East**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab920965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: BEN (bn_in)\n",
      "============================================================\n",
      "Found 348 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/asm_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs3_r, hyps_s2tt3_r, hyps_t2tt3_r, preds_s2s3_r, preds_t2s3_r = run_translation_for_language(\"asm\",\"as_in\",\"ben\",\"bn_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b98927a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for ASM â†’ BN_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 7.432998184513635,\n",
       " 'S2TT_chrF++': 31.55519565124434,\n",
       " 'S2TT_chrF2++': 31.55519565124434,\n",
       " 'S2TT_WER': 0.8961094100191561,\n",
       " 'T2TT_BLEU': 9.103526405546068,\n",
       " 'T2TT_chrF++': 32.93628823601946,\n",
       " 'T2TT_chrF2++': 32.93628823601946,\n",
       " 'T2TT_WER': 0.8526534827526825,\n",
       " 'S2ST_BLEU': 3.7199102928113716,\n",
       " 'S2ST_chrF++': 31.326555062235627,\n",
       " 'S2ST_chrF2++': 31.326555062235627,\n",
       " 'S2ST_WER': 0.9749197934370839,\n",
       " 'T2ST_BLEU': 6.468490584192431,\n",
       " 'T2ST_chrF++': 30.014360940963503,\n",
       " 'T2ST_chrF2++': 30.014360940963503,\n",
       " 'T2ST_WER': 0.9683734937759376}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"asm\",\"bn_in\", refs3_r, hyps_s2tt3_r, hyps_t2tt3_r, preds_s2s3_r, preds_t2s3_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ceab85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: BEN (bn_in)\n",
      "============================================================\n",
      "Found 333 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/ory_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs4_r, hyps_s2tt4_r, hyps_t2tt4_r, preds_s2s4_r, preds_t2s4_r = run_translation_for_language(\"ory\",\"or_in\",\"ben\",\"bn_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "806a96e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for ORY â†’ BN_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 7.994607499472017,\n",
       " 'S2TT_chrF++': 43.07068186882795,\n",
       " 'S2TT_chrF2++': 43.07068186882795,\n",
       " 'S2TT_WER': 0.8528774458964289,\n",
       " 'T2TT_BLEU': 19.83544145418288,\n",
       " 'T2TT_chrF++': 52.195821217185156,\n",
       " 'T2TT_chrF2++': 52.195821217185156,\n",
       " 'T2TT_WER': 0.8144597780392709,\n",
       " 'S2ST_BLEU': 3.4933841821869938,\n",
       " 'S2ST_chrF++': 32.07475524723871,\n",
       " 'S2ST_chrF2++': 32.07475524723871,\n",
       " 'S2ST_WER': 0.9747689093694288,\n",
       " 'T2ST_BLEU': 3.7199102928113716,\n",
       " 'T2ST_chrF++': 45.734217315889346,\n",
       " 'T2ST_chrF2++': 45.734217315889346,\n",
       " 'T2ST_WER': 0.9641954585970011}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"ory\",\"bn_in\", refs4_r, hyps_s2tt4_r, hyps_t2tt4_r, preds_s2s4_r, preds_t2s4_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a680804",
   "metadata": {},
   "source": [
    "**South**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1de24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 292 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/tam_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs6_r, hyps_s2tt6_r, hyps_t2tt6_r, preds_s2s6_r, preds_t2s6_r = run_translation_for_language(\"tam\",\"ta_in\",\"tel\",\"te_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ffce779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TAM â†’ TE_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 13.217947626377288,\n",
       " 'S2TT_chrF++': 44.08510530706513,\n",
       " 'S2TT_chrF2++': 44.08510530706513,\n",
       " 'S2TT_WER': 0.9112131304780734,\n",
       " 'T2TT_BLEU': 15.718877363021207,\n",
       " 'T2TT_chrF++': 48.03759662462975,\n",
       " 'T2TT_chrF2++': 48.03759662462975,\n",
       " 'T2TT_WER': 0.8330915214576137,\n",
       " 'S2ST_BLEU': 3.377156414337854,\n",
       " 'S2ST_chrF++': 22.86499894392577,\n",
       " 'S2ST_chrF2++': 22.86499894392577,\n",
       " 'S2ST_WER': 0.9891606546709331,\n",
       " 'T2ST_BLEU': 6.917184228205472,\n",
       " 'T2ST_chrF++': 33.32637761255218,\n",
       " 'T2ST_chrF2++': 33.32637761255218,\n",
       " 'T2ST_WER': 0.9736780329948216}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tam\",\"te_in\", refs6_r, hyps_s2tt6_r, hyps_t2tt6_r, preds_s2s6_r, preds_t2s6_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "190d5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 298 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/mal_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs7_r, hyps_s2tt7_r, hyps_t2tt7_r, preds_s2s7_r, preds_t2s7_r = run_translation_for_language(\"mal\",\"ml_in\",\"tel\",\"te_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa86b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for MAL â†’ TE_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 11.359354890271161,\n",
       " 'S2TT_chrF++': 39.615953088508626,\n",
       " 'S2TT_chrF2++': 39.615953088508626,\n",
       " 'S2TT_WER': 0.8768997992263303,\n",
       " 'T2TT_BLEU': 15.467294147156862,\n",
       " 'T2TT_chrF++': 41.58621152662165,\n",
       " 'T2TT_chrF2++': 41.58621152662165,\n",
       " 'T2TT_WER': 0.8201387993015712,\n",
       " 'S2ST_BLEU': 4.02724819242185,\n",
       " 'S2ST_chrF++': 6.378643553529761,\n",
       " 'S2ST_chrF2++': 6.378643553529761,\n",
       " 'S2ST_WER': 0.9735397631012651,\n",
       " 'T2ST_BLEU': 6.754312828675707,\n",
       " 'T2ST_chrF++': 28.611049735568827,\n",
       " 'T2ST_chrF2++': 28.611049735568827,\n",
       " 'T2ST_WER': 0.9575591097225604}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"mal\",\"te_in\", refs7_r, hyps_s2tt7_r, hyps_t2tt7_r, preds_s2s7_r, preds_t2s7_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea7b383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: TEL (te_in)\n",
      "============================================================\n",
      "Found 297 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-X-Direct/Reverse/f-X-X-Direct-CSVs/kan_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs8_r, hyps_s2tt8_r, hyps_t2tt8_r, preds_s2s8_r, preds_t2s8_r = run_translation_for_language(\"kan\",\"kn_in\",\"tel\",\"te_in\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1eea514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for KAN â†’ TE_IN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 13.94120548961102,\n",
       " 'S2TT_chrF++': 48.65628895837739,\n",
       " 'S2TT_chrF2++': 48.65628895837739,\n",
       " 'S2TT_WER': 0.8540457677299435,\n",
       " 'T2TT_BLEU': 13.94120548961102,\n",
       " 'T2TT_chrF++': 47.98767774606964,\n",
       " 'T2TT_chrF2++': 47.98767774606964,\n",
       " 'T2TT_WER': 0.8073695541161855,\n",
       " 'S2ST_BLEU': 2.8398387225677895,\n",
       " 'S2ST_chrF++': 26.743076465908043,\n",
       " 'S2ST_chrF2++': 26.743076465908043,\n",
       " 'S2ST_WER': 0.9787201952661825,\n",
       " 'T2ST_BLEU': 3.1251907639724417,\n",
       " 'T2ST_chrF++': 30.554146715793955,\n",
       " 'T2ST_chrF2++': 30.554146715793955,\n",
       " 'T2ST_WER': 0.9506681620942768}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"kan\",\"te_in\", refs8_r, hyps_s2tt8_r, hyps_t2tt8_r, preds_s2s8_r, preds_t2s8_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhav_venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
