{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c668646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mmap\n",
    "import numpy\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ffmpeg\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from seamless_communication.inference import Translator\n",
    "from seamless_communication.streaming.dataloaders.s2tt import SileroVADSilenceRemover\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba66732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from seamless_communication.inference import Translator\n",
    "from jiwer import wer\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cc9a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Translator object with a multitask model, vocoder on the GPU.\n",
    "\n",
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda\"), # Changed from \"cuda:0\" to \"cpu\"\n",
    "    dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef25c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "def resample_to_16k(audio, orig_sr):\n",
    "    # implement resampling logic here, e.g. torchaudio.transforms.Resample\n",
    "    return torchaudio.transforms.Resample(orig_sr, 16000)(torch.tensor(audio)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a756c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Load Whisper-Large once (outside function, so itâ€™s not reloaded every call)\n",
    "whisper_model = whisper.load_model(\"large-v3\", device=\"cuda\")\n",
    "\n",
    "whisper.audio.FFMPEG_PATH = \"/home/aj/Bhavna/ffmpeg_bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1227fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seamless_communication\n",
    "\n",
    "from seamless_communication.inference import SequenceGeneratorOptions\n",
    "text_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    "    #temperature=0.7,   # 0 for deterministic, >0 adds diversity\n",
    ")\n",
    "\n",
    "# Beam search for unit hypotheses\n",
    "unit_opts = SequenceGeneratorOptions(\n",
    "    beam_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483a3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7531021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, lang, out_dir=\"/scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{lang}_results.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved results to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50154de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537662d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenizer(texts, lang_code):\n",
    "    \"\"\"Apply IndicNLP/Urdu tokenization for Enâ†’Indic evaluation\"\"\"\n",
    "    if not texts:\n",
    "        return texts\n",
    "    elif lang_code in [\"hi\", \"bn\", \"te\", \"ta\", \"ml\", \"kn\", \"gu\", \"mr\", \"pa\", \"or\"]:\n",
    "        return [\" \".join(indic_tokenize.trivial_tokenize(t, lang=lang_code)) for t in texts]\n",
    "    else:  # fallback (English etc.)\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46862ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_translation_for_language(sm4t_src_lang,fleurs_src_lang,sm4t_tgt_lang, fleurs_tgt_lang, full_tasks=True):\n",
    "    \"\"\"\n",
    "    Run translation pipeline for one language.\n",
    "    full_tasks=True â†’ Run all 4 tasks\n",
    "    full_tasks=False â†’ Run only S2TT, T2TT\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ”¹ Processing Target Language: {sm4t_tgt_lang.upper()} ({fleurs_tgt_lang})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load datasets\n",
    "    src_dataset = load_dataset(\"google/fleurs\", fleurs_src_lang, split=\"test\")\n",
    "    tgt_dataset = load_dataset(\"google/fleurs\", fleurs_tgt_lang, split=\"test\")\n",
    "\n",
    "    src_by_id = {item[\"id\"]: item for item in src_dataset}\n",
    "    tgt_by_id = {item[\"id\"]: item for item in tgt_dataset}\n",
    "    common_ids = sorted(set(src_by_id.keys()) & set(tgt_by_id.keys()))\n",
    "\n",
    "    print(f\"Found {len(common_ids)} parallel sentences\")\n",
    "\n",
    "    references, hypotheses_s2tt, hypotheses_t2tt = [], [], []\n",
    "    predicted_s2s, predicted_t2s = [], []\n",
    "    source_texts = []\n",
    "\n",
    "    for sentence_id in common_ids:\n",
    "        src = src_by_id[sentence_id]\n",
    "        tgt = tgt_by_id[sentence_id]\n",
    "\n",
    "        src_audio = src[\"audio\"][\"array\"]\n",
    "        src_sr = src[\"audio\"][\"sampling_rate\"]\n",
    "        src_text = src[\"transcription\"]\n",
    "        tgt_text = tgt[\"transcription\"]\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        source_texts.append(src_text)\n",
    "\n",
    "        if src_sr != 16000:\n",
    "            src_audio = resample_to_16k(src_audio, src_sr)\n",
    "\n",
    "        base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/input_audios_of_eng\"\n",
    "        lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "        os.makedirs(lang_dir, exist_ok=True)\n",
    "        audio_path = os.path.join(lang_dir, f\"input_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "        torchaudio.save(audio_path, torch.tensor(src_audio).unsqueeze(0), 16000)\n",
    "\n",
    "        # --- S2TT ---\n",
    "        s2tt_out, _ = translator.predict(\n",
    "            input=audio_path, task_str=\"s2tt\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_s2tt.append(normalize(str(s2tt_out[0])))\n",
    "\n",
    "        # --- T2TT ---\n",
    "        t2tt_out, _ = translator.predict(\n",
    "            input=src_text, task_str=\"t2tt\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts\n",
    "        )\n",
    "        hypotheses_t2tt.append(normalize(str(t2tt_out[0])))\n",
    "\n",
    "        if full_tasks:\n",
    "            # --- S2ST + Whisper ASR ---\n",
    "            _, s2s_audio_out = translator.predict(\n",
    "                input=audio_path, task_str=\"s2st\", tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/s2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            s2s_path= os.path.join(lang_dir, f\"s2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                s2s_path,\n",
    "                s2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                s2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            s2s_result = whisper_model.transcribe(\n",
    "                audio=s2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,   # greedy, deterministic\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_s2s.append(normalize(s2s_result[\"text\"]))\n",
    "\n",
    "            # --- T2ST + Whisper ASR ---\n",
    "            _, t2s_audio_out = translator.predict(\n",
    "                input=src_text, task_str=\"t2st\", src_lang=sm4t_src_lang, tgt_lang=sm4t_tgt_lang,text_generation_opts=text_opts,unit_generation_opts=unit_opts\n",
    "            )\n",
    "            base_dir = \"/scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/t2s_outputs\"\n",
    "            lang_dir = os.path.join(base_dir, sm4t_src_lang)\n",
    "            os.makedirs(lang_dir, exist_ok=True)\n",
    "            t2s_path = os.path.join(lang_dir, f\"t2s_{sm4t_tgt_lang}_{sentence_id}.wav\")\n",
    "\n",
    "            torchaudio.save(\n",
    "                t2s_path,\n",
    "                t2s_audio_out.audio_wavs[0][0].to(torch.float32).cpu(),\n",
    "                t2s_audio_out.sample_rate,\n",
    "            )\n",
    "\n",
    "            # Use Whisper-Large for ASR\n",
    "            t2s_result = whisper_model.transcribe(\n",
    "                audio=t2s_path,\n",
    "                task=\"transcribe\",\n",
    "                temperature=0.0,\n",
    "                beam_size=None\n",
    "            )\n",
    "            predicted_t2s.append(normalize(t2s_result[\"text\"]))\n",
    "\n",
    "    # Build dataframe\n",
    "    data = {\n",
    "        \"source_text\": source_texts,\n",
    "        \"reference_text\": [r[0] for r in references],\n",
    "        \"S2TT_prediction\": hypotheses_s2tt,\n",
    "        \"T2TT_prediction\": hypotheses_t2tt\n",
    "    }\n",
    "    if full_tasks:\n",
    "        data[\"S2ST_ASR\"] = predicted_s2s\n",
    "        data[\"T2ST_ASR\"] = predicted_t2s\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    save_dataframe(df, sm4t_tgt_lang)\n",
    "\n",
    "    return references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9566ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_chrf\n",
    "\n",
    "def compute_metrics(src_lang, tgt_lang, references, hypotheses_s2tt, hypotheses_t2tt, predicted_s2s, predicted_t2s):\n",
    "    print(f\"\\nComputing metrics for {src_lang.upper()} â†’ {tgt_lang.upper()}\")\n",
    "\n",
    "    # Normalize hyps\n",
    "    hypotheses_s2tt = [str(h) for h in hypotheses_s2tt]\n",
    "    hypotheses_t2tt = [str(h) for h in hypotheses_t2tt]\n",
    "    predicted_s2s   = [str(h) for h in predicted_s2s]\n",
    "    predicted_t2s   = [str(h) for h in predicted_t2s]\n",
    "\n",
    "    # Normalize refs\n",
    "    references_norm = [[str(r) for r in refset] for refset in references]\n",
    "    multi_references = list(zip(*references_norm))\n",
    "\n",
    "    # ---- Tokenization switch ----\n",
    "    if src_lang == \"en\":  \n",
    "        # Eng â†’ Indic â†’ tokenize target\n",
    "        hypotheses_s2tt = apply_tokenizer(hypotheses_s2tt, tgt_lang)\n",
    "        hypotheses_t2tt = apply_tokenizer(hypotheses_t2tt, tgt_lang)\n",
    "        predicted_s2s   = apply_tokenizer(predicted_s2s, tgt_lang)\n",
    "        predicted_t2s   = apply_tokenizer(predicted_t2s, tgt_lang)\n",
    "        tokenized_refs = [apply_tokenizer(refs, tgt_lang) for refs in multi_references]\n",
    "    else:\n",
    "        # Indic â†’ En â†’ use sacreBLEU default tokenizer\n",
    "        tokenized_refs = multi_references\n",
    "\n",
    "    tokenized_refs = list(zip(*tokenized_refs))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # --------------------\n",
    "    # S2TT\n",
    "    # --------------------\n",
    "    metrics[\"S2TT_BLEU\"]      = corpus_bleu(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF++\"]    = corpus_chrf(hypotheses_s2tt, tokenized_refs).score\n",
    "    metrics[\"S2TT_chrF2++\"]   = corpus_chrf(hypotheses_s2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"S2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_s2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2TT\n",
    "    # --------------------\n",
    "    metrics[\"T2TT_BLEU\"]      = corpus_bleu(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF++\"]    = corpus_chrf(hypotheses_t2tt, tokenized_refs).score\n",
    "    metrics[\"T2TT_chrF2++\"]   = corpus_chrf(hypotheses_t2tt, tokenized_refs, beta=2).score\n",
    "    metrics[\"T2TT_WER\"]       = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, hypotheses_t2tt)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # S2ST\n",
    "    # --------------------\n",
    "    if predicted_s2s:\n",
    "        metrics[\"S2ST_BLEU\"]    = corpus_bleu(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF++\"]  = corpus_chrf(predicted_s2s, tokenized_refs).score\n",
    "        metrics[\"S2ST_chrF2++\"] = corpus_chrf(predicted_s2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"S2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_s2s)) / len(references_norm)\n",
    "\n",
    "    # --------------------\n",
    "    # T2ST\n",
    "    # --------------------\n",
    "    if predicted_t2s:\n",
    "        metrics[\"T2ST_BLEU\"]    = corpus_bleu(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF++\"]  = corpus_chrf(predicted_t2s, tokenized_refs).score\n",
    "        metrics[\"T2ST_chrF2++\"] = corpus_chrf(predicted_t2s, tokenized_refs, beta=2).score\n",
    "        metrics[\"T2ST_WER\"]     = sum(wer(ref[0], hyp) for ref, hyp in zip(references_norm, predicted_t2s)) / len(references_norm)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c4dcc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 265 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1 = run_translation_for_language(\"hin\", \"hi_in\",\"eng\", \"en_us\", full_tasks=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1af2599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2 = run_translation_for_language(\"ben\", \"bn_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2b8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 302 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs3, hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3 = run_translation_for_language(\"tel\", \"te_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3b8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 336 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4 = run_translation_for_language(\"tam\", \"ta_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd0596ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 344 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs5,hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5 = run_translation_for_language(\"mal\", \"ml_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41cb4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs6,hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6 = run_translation_for_language(\"guj\", \"gu_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b44be2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs7,hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7 = run_translation_for_language(\"mar\", \"mr_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6cd79bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 279 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs8,hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8 = run_translation_for_language(\"pan\", \"pa_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e15552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 344 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs9,hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9 = run_translation_for_language(\"kan\", \"kn_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b4363e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 334 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs10,hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10 = run_translation_for_language(\"ory\", \"or_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66abc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 230 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs11,hyps_s2tt11, hyps_t2tt11, preds_s2s11, preds_t2s11 = run_translation_for_language(\"urd\", \"ur_pk\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e306128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 349 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs12,hyps_s2tt12, hyps_t2tt12, preds_s2s12, preds_t2s12 = run_translation_for_language(\"asm\",\"as_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e83670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 350 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs13,hyps_s2tt13, hyps_t2tt13, preds_s2s13, preds_t2s13 = run_translation_for_language(\"snd\", \"sd_in\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22cb0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ”¹ Processing Target Language: ENG (en_us)\n",
      "============================================================\n",
      "Found 343 parallel sentences\n",
      "Saved results to /scratch/aj/Bhavna/bhav_venv_311/f-X-Eng-Direct/f-X-Eng-Direct-CSVs/eng_results.csv\n"
     ]
    }
   ],
   "source": [
    "refs14,hyps_s2tt14, hyps_t2tt14, preds_s2s14, preds_t2s14 = run_translation_for_language(\"npi\",\"ne_np\",\"eng\", \"en_us\", full_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf745e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for HIN â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 19.259887228376275,\n",
       " 'S2TT_chrF++': 47.064516706148865,\n",
       " 'S2TT_chrF2++': 47.064516706148865,\n",
       " 'S2TT_WER': 0.5769781283054644,\n",
       " 'T2TT_BLEU': 100.00000000000004,\n",
       " 'T2TT_chrF++': 100.0,\n",
       " 'T2TT_chrF2++': 100.0,\n",
       " 'T2TT_WER': 0.4829589650612814,\n",
       " 'S2ST_BLEU': 18.951629567590746,\n",
       " 'S2ST_chrF++': 44.4801824800045,\n",
       " 'S2ST_chrF2++': 44.4801824800045,\n",
       " 'S2ST_WER': 0.5744392525630683,\n",
       " 'T2ST_BLEU': 100.00000000000004,\n",
       " 'T2ST_chrF++': 100.0,\n",
       " 'T2ST_chrF2++': 100.0,\n",
       " 'T2ST_WER': 0.5062129707006541}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"hin\",\"en_us\", refs1, hyps_s2tt1, hyps_t2tt1, preds_s2s1, preds_t2s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1eb879e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for BEN â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 11.986062961075742,\n",
       " 'S2TT_chrF++': 51.61641017074737,\n",
       " 'S2TT_chrF2++': 51.61641017074737,\n",
       " 'S2TT_WER': 0.6057547991640091,\n",
       " 'T2TT_BLEU': 12.470873588504128,\n",
       " 'T2TT_chrF++': 44.03763089981711,\n",
       " 'T2TT_chrF2++': 44.03763089981711,\n",
       " 'T2TT_WER': 0.5433760961388682,\n",
       " 'S2ST_BLEU': 12.169109229511132,\n",
       " 'S2ST_chrF++': 53.931480319342725,\n",
       " 'S2ST_chrF2++': 53.931480319342725,\n",
       " 'S2ST_WER': 0.6105122039137028,\n",
       " 'T2ST_BLEU': 13.592883763682499,\n",
       " 'T2ST_chrF++': 42.00545781690605,\n",
       " 'T2ST_chrF2++': 42.00545781690605,\n",
       " 'T2ST_WER': 0.5551223983302469}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"ben\",\"en_us\", refs2, hyps_s2tt2, hyps_t2tt2, preds_s2s2, preds_t2s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2332cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TEL â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 9.578464408619825,\n",
       " 'S2TT_chrF++': 44.29120051573812,\n",
       " 'S2TT_chrF2++': 44.29120051573812,\n",
       " 'S2TT_WER': 0.6132852423109971,\n",
       " 'T2TT_BLEU': 60.427507947135354,\n",
       " 'T2TT_chrF++': 84.21637053128809,\n",
       " 'T2TT_chrF2++': 84.21637053128809,\n",
       " 'T2TT_WER': 0.5262495941621558,\n",
       " 'S2ST_BLEU': 8.73716785171588,\n",
       " 'S2ST_chrF++': 39.62467006078068,\n",
       " 'S2ST_chrF2++': 39.62467006078068,\n",
       " 'S2ST_WER': 0.6039635892802974,\n",
       " 'T2ST_BLEU': 60.427507947135354,\n",
       " 'T2ST_chrF++': 84.21637053128809,\n",
       " 'T2ST_chrF2++': 84.21637053128809,\n",
       " 'T2ST_WER': 0.5351444780751428}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tel\",\"en_us\", refs3, hyps_s2tt3, hyps_t2tt3, preds_s2s3, preds_t2s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e749ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for TAM â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 51.60202040000685,\n",
       " 'S2TT_chrF++': 62.48674189397521,\n",
       " 'S2TT_chrF2++': 62.48674189397521,\n",
       " 'S2TT_WER': 0.6711805367864453,\n",
       " 'T2TT_BLEU': 11.678449443205002,\n",
       " 'T2TT_chrF++': 49.92483236542206,\n",
       " 'T2TT_chrF2++': 49.92483236542206,\n",
       " 'T2TT_WER': 0.5663497144591616,\n",
       " 'S2ST_BLEU': 51.60202040000685,\n",
       " 'S2ST_chrF++': 62.48674189397521,\n",
       " 'S2ST_chrF2++': 62.48674189397521,\n",
       " 'S2ST_WER': 0.658504086797589,\n",
       " 'T2ST_BLEU': 11.678449443205002,\n",
       " 'T2ST_chrF++': 49.92483236542206,\n",
       " 'T2ST_chrF2++': 49.92483236542206,\n",
       " 'T2ST_WER': 0.5782981519860814}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"tam\",\"en_us\", refs4, hyps_s2tt4, hyps_t2tt4, preds_s2s4, preds_t2s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38346e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for MAL â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 32.4069446727242,\n",
       " 'S2TT_chrF++': 51.58750220445118,\n",
       " 'S2TT_chrF2++': 51.58750220445118,\n",
       " 'S2TT_WER': 0.6229671568681744,\n",
       " 'T2TT_BLEU': 63.71804857892112,\n",
       " 'T2TT_chrF++': 70.35589629053496,\n",
       " 'T2TT_chrF2++': 70.35589629053496,\n",
       " 'T2TT_WER': 0.539874157229546,\n",
       " 'S2ST_BLEU': 32.4069446727242,\n",
       " 'S2ST_chrF++': 51.58750220445118,\n",
       " 'S2ST_chrF2++': 51.58750220445118,\n",
       " 'S2ST_WER': 0.6148951631734149,\n",
       " 'T2ST_BLEU': 63.71804857892112,\n",
       " 'T2ST_chrF++': 70.35589629053496,\n",
       " 'T2ST_chrF2++': 70.35589629053496,\n",
       " 'T2ST_WER': 0.54284509294128}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"mal\",\"en_us\", refs5, hyps_s2tt5, hyps_t2tt5, preds_s2s5, preds_t2s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fd5c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for GUJ â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 19.835441454182888,\n",
       " 'S2TT_chrF++': 49.43201474537644,\n",
       " 'S2TT_chrF2++': 49.43201474537644,\n",
       " 'S2TT_WER': 0.5428466688130611,\n",
       " 'T2TT_BLEU': 34.329452398451956,\n",
       " 'T2TT_chrF++': 60.08415368642262,\n",
       " 'T2TT_chrF2++': 60.08415368642262,\n",
       " 'T2TT_WER': 0.47140989436656927,\n",
       " 'S2ST_BLEU': 19.835441454182888,\n",
       " 'S2ST_chrF++': 49.08333931577539,\n",
       " 'S2ST_chrF2++': 49.08333931577539,\n",
       " 'S2ST_WER': 0.5527190922758902,\n",
       " 'T2ST_BLEU': 34.329452398451956,\n",
       " 'T2ST_chrF++': 60.08415368642262,\n",
       " 'T2ST_chrF2++': 60.08415368642262,\n",
       " 'T2ST_WER': 0.4810689032393332}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"guj\",\"en_us\", refs6, hyps_s2tt6, hyps_t2tt6, preds_s2s6, preds_t2s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3628f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for MAR â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 45.274718709528955,\n",
       " 'S2TT_chrF++': 60.303239136880016,\n",
       " 'S2TT_chrF2++': 60.303239136880016,\n",
       " 'S2TT_WER': 0.6141061966883621,\n",
       " 'T2TT_BLEU': 21.651956746181064,\n",
       " 'T2TT_chrF++': 53.01880673972587,\n",
       " 'T2TT_chrF2++': 53.01880673972587,\n",
       " 'T2TT_WER': 0.5098966102925325,\n",
       " 'S2ST_BLEU': 45.274718709528955,\n",
       " 'S2ST_chrF++': 60.303239136880016,\n",
       " 'S2ST_chrF2++': 60.303239136880016,\n",
       " 'S2ST_WER': 0.6104087010091004,\n",
       " 'T2ST_BLEU': 21.186050864016675,\n",
       " 'T2ST_chrF++': 52.95548816688813,\n",
       " 'T2ST_chrF2++': 52.95548816688813,\n",
       " 'T2ST_WER': 0.5190659386774854}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"mar\",\"en_us\", refs7, hyps_s2tt7, hyps_t2tt7, preds_s2s7, preds_t2s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e4fdfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for PAN â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 14.980800232509305,\n",
       " 'S2TT_chrF++': 58.62758024251515,\n",
       " 'S2TT_chrF2++': 58.62758024251515,\n",
       " 'S2TT_WER': 0.5965989711491985,\n",
       " 'T2TT_BLEU': 29.48993986902436,\n",
       " 'T2TT_chrF++': 69.2584161771794,\n",
       " 'T2TT_chrF2++': 69.2584161771794,\n",
       " 'T2TT_WER': 0.4757341206345312,\n",
       " 'S2ST_BLEU': 9.625807217196785,\n",
       " 'S2ST_chrF++': 54.53016839979288,\n",
       " 'S2ST_chrF2++': 54.53016839979288,\n",
       " 'S2ST_WER': 0.5960282977583556,\n",
       " 'T2ST_BLEU': 48.34389064001791,\n",
       " 'T2ST_chrF++': 72.99348554655523,\n",
       " 'T2ST_chrF2++': 72.99348554655523,\n",
       " 'T2ST_WER': 0.48319325921869083}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"pan\",\"en_us\", refs8, hyps_s2tt8, hyps_t2tt8, preds_s2s8, preds_t2s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "850b13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for KAN â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 47.587330964125215,\n",
       " 'S2TT_chrF++': 67.22912468216506,\n",
       " 'S2TT_chrF2++': 67.22912468216506,\n",
       " 'S2TT_WER': 0.6320570666442101,\n",
       " 'T2TT_BLEU': 76.24658586234858,\n",
       " 'T2TT_chrF++': 82.57206226180148,\n",
       " 'T2TT_chrF2++': 82.57206226180148,\n",
       " 'T2TT_WER': 0.575623358094392,\n",
       " 'S2ST_BLEU': 47.587330964125215,\n",
       " 'S2ST_chrF++': 67.22912468216506,\n",
       " 'S2ST_chrF2++': 67.22912468216506,\n",
       " 'S2ST_WER': 0.627693012033382,\n",
       " 'T2ST_BLEU': 76.24658586234858,\n",
       " 'T2ST_chrF++': 82.57206226180148,\n",
       " 'T2ST_chrF2++': 82.57206226180148,\n",
       " 'T2ST_WER': 0.5870343522113848}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"kan\",\"en_us\", refs9, hyps_s2tt9, hyps_t2tt9, preds_s2s9, preds_t2s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caa032be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for ORY â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 48.740622698799406,\n",
       " 'S2TT_chrF++': 72.95153347169273,\n",
       " 'S2TT_chrF2++': 72.95153347169273,\n",
       " 'S2TT_WER': 0.6275503817546304,\n",
       " 'T2TT_BLEU': 82.82477531331043,\n",
       " 'T2TT_chrF++': 91.60457336453659,\n",
       " 'T2TT_chrF2++': 91.60457336453659,\n",
       " 'T2TT_WER': 0.5113733669275848,\n",
       " 'S2ST_BLEU': 48.740622698799406,\n",
       " 'S2ST_chrF++': 72.95153347169273,\n",
       " 'S2ST_chrF2++': 72.95153347169273,\n",
       " 'S2ST_WER': 0.6268162642308952,\n",
       " 'T2ST_BLEU': 82.82477531331043,\n",
       " 'T2ST_chrF++': 91.60457336453659,\n",
       " 'T2ST_chrF2++': 91.60457336453659,\n",
       " 'T2ST_WER': 0.5130236769776545}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"ory\",\"en_us\", refs10, hyps_s2tt10, hyps_t2tt10, preds_s2s10, preds_t2s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "212d5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for URD â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 35.55304670431184,\n",
       " 'S2TT_chrF++': 64.03077002758981,\n",
       " 'S2TT_chrF2++': 64.03077002758981,\n",
       " 'S2TT_WER': 0.6189562220362608,\n",
       " 'T2TT_BLEU': 43.78826865860791,\n",
       " 'T2TT_chrF++': 75.07593076816529,\n",
       " 'T2TT_chrF2++': 75.07593076816529,\n",
       " 'T2TT_WER': 0.5121603399715183,\n",
       " 'S2ST_BLEU': 35.55304670431184,\n",
       " 'S2ST_chrF++': 64.03077002758981,\n",
       " 'S2ST_chrF2++': 64.03077002758981,\n",
       " 'S2ST_WER': 0.6145540594050083,\n",
       " 'T2ST_BLEU': 43.78826865860791,\n",
       " 'T2ST_chrF++': 75.07593076816529,\n",
       " 'T2ST_chrF2++': 75.07593076816529,\n",
       " 'T2ST_WER': 0.516878890245686}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"urd\",\"en_us\", refs11, hyps_s2tt11, hyps_t2tt11, preds_s2s11, preds_t2s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed652ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for ASM â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 24.669426816409512,\n",
       " 'S2TT_chrF++': 57.311094385046566,\n",
       " 'S2TT_chrF2++': 57.311094385046566,\n",
       " 'S2TT_WER': 0.6704331654481143,\n",
       " 'T2TT_BLEU': 27.301208627090666,\n",
       " 'T2TT_chrF++': 56.09181867259812,\n",
       " 'T2TT_chrF2++': 56.09181867259812,\n",
       " 'T2TT_WER': 0.5840625564985533,\n",
       " 'S2ST_BLEU': 24.669426816409512,\n",
       " 'S2ST_chrF++': 57.311094385046566,\n",
       " 'S2ST_chrF2++': 57.311094385046566,\n",
       " 'S2ST_WER': 0.6639281743212848,\n",
       " 'T2ST_BLEU': 27.301208627090666,\n",
       " 'T2ST_chrF++': 56.09181867259812,\n",
       " 'T2ST_chrF2++': 56.09181867259812,\n",
       " 'T2ST_WER': 0.5911567851255853}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"asm\",\"en_us\", refs12, hyps_s2tt12, hyps_t2tt12, preds_s2s12, preds_t2s12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1051cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for SND â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 14.266268462755136,\n",
       " 'S2TT_chrF++': 27.438009935295526,\n",
       " 'S2TT_chrF2++': 27.438009935295526,\n",
       " 'S2TT_WER': 0.8930249785976819,\n",
       " 'T2TT_BLEU': 28.64284647416118,\n",
       " 'T2TT_chrF++': 59.64667401553315,\n",
       " 'T2TT_chrF2++': 59.64667401553315,\n",
       " 'T2TT_WER': 0.5061408291347962,\n",
       " 'S2ST_BLEU': 14.266268462755136,\n",
       " 'S2ST_chrF++': 27.438009935295526,\n",
       " 'S2ST_chrF2++': 27.438009935295526,\n",
       " 'S2ST_WER': 0.881408672334438,\n",
       " 'T2ST_BLEU': 28.64284647416118,\n",
       " 'T2ST_chrF++': 59.64667401553315,\n",
       " 'T2ST_chrF2++': 59.64667401553315,\n",
       " 'T2ST_WER': 0.5345305138838374}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\"snd\",\"en_us\", refs13, hyps_s2tt13, hyps_t2tt13, preds_s2s13, preds_t2s13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing metrics for NPI â†’ EN_US\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S2TT_BLEU': 31.85277558379779,\n",
       " 'S2TT_chrF++': 62.713740948011974,\n",
       " 'S2TT_chrF2++': 62.713740948011974,\n",
       " 'S2TT_WER': 0.5897884618031969,\n",
       " 'T2TT_BLEU': 47.75205461960747,\n",
       " 'T2TT_chrF++': 81.80625838235312,\n",
       " 'T2TT_chrF2++': 81.80625838235312,\n",
       " 'T2TT_WER': 0.48998421964692784,\n",
       " 'S2ST_BLEU': 31.85277558379779,\n",
       " 'S2ST_chrF++': 62.713740948011974,\n",
       " 'S2ST_chrF2++': 62.713740948011974,\n",
       " 'S2ST_WER': 0.5927473642050798,\n",
       " 'T2ST_BLEU': 66.5912587079685,\n",
       " 'T2ST_chrF++': 84.97440206659982,\n",
       " 'T2ST_chrF2++': 84.97440206659982,\n",
       " 'T2ST_WER': 0.4983339247508748}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "compute_metrics(\"npi\",\"en_us\", refs14, hyps_s2tt14, hyps_t2tt14, preds_s2s14, preds_t2s14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258b033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhav_venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
